{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic pricing\n",
    "\n",
    "* A pricing strategy that adjusts the price of a product or service in real-time\n",
    "* Based on factors:\n",
    "  * Market demand\n",
    "  * Competition\n",
    "  * Customer behaviour\n",
    "* Goal is to maximize profits \n",
    "  * By finding the optimal price point that customers are willing to pay\n",
    "  * Costs associated with producing and selling the product\n",
    "\n",
    "\n",
    "## Algorithms\n",
    "\n",
    "### Rule-based\n",
    "Uses pre-defined rules to set prices i.e. increase price if demand is high or lower price if demand is low.\n",
    "\n",
    "### Time-series forecasting\n",
    "Uses historical data to forecast future demand and adjust prices accordingly. Takes into account seasonal patterns and trends to optimize pricing.\n",
    "\n",
    "### Machine Learning algorithm\n",
    "Use historical data to learn patterns and adjust prices based on predictive models. Can include regression analysis, decision trees, and neural networks.\n",
    "\n",
    "### Reinforcement Learning algorithm\n",
    "Uses trial and error to optimize pricing. Algorithm makes decisions based on feedback from customer behaviour and ajusts prices to maximize profit.\n",
    "\n",
    "### Multi-armed bandit algorithm\n",
    "Used in situations where there are multiple products or pricing options. Uses trial and error to test different pricing strategies and learns which ones are most effective in maximizing profit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fbprophet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_absolute_error\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfbprophet\u001b[39;00m \u001b[39mimport\u001b[39;00m Prophet\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fbprophet'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from fbprophet import Prophet\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join datasets\n",
    "\n",
    "* Brazilian E-commerce data in multiple CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read multiple CSV files\n",
    "FILE_PATH = \"/workspaces/dynamic_pricing/data/\"\n",
    "\n",
    "order_items    = pd.read_csv(FILE_PATH + \"olist_order_items_dataset.csv\")\n",
    "orders         = pd.read_csv(FILE_PATH + \"olist_orders_dataset.csv\")\n",
    "order_payments = pd.read_csv(FILE_PATH + \"olist_order_payments_dataset.csv\")\n",
    "products       = pd.read_csv(FILE_PATH + \"olist_products_dataset.csv\")\n",
    "customers      = pd.read_csv(FILE_PATH + \"olist_customers_dataset.csv\")\n",
    "sellers        = pd.read_csv(FILE_PATH + \"olist_sellers_dataset.csv\")\n",
    "product_category_translation = pd.read_csv(FILE_PATH + \"product_category_name_translation.csv\")\n",
    "\n",
    "# Merge datasets\n",
    "merged = order_items.merge(orders, on='order_id') \\\n",
    "                    .merge(order_payments, on=['order_id']) \\\n",
    "                    .merge(products, on='product_id') \\\n",
    "                    .merge(customers, on='customer_id') \\\n",
    "                    .merge(sellers, on='seller_id') \\\n",
    "                    .merge(product_category_translation, on='product_category_name')\n",
    "\n",
    "# Save the consolidated dataset to a CSV file\n",
    "merged.to_csv(FILE_PATH + 'brazilian_ecommerce_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_random_forest(dataset):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(dataset)\n",
    "    \n",
    "    # Preprocess the data\n",
    "    # Drop irrelevant columns and handle missing data\n",
    "    df = df.drop(['seller_id', 'freight_value'], axis=1)\n",
    "    df = df[df['customer_state'].isin([\"SP\",\"RJ\",\"MG\"])]\n",
    "    df = df[['product_category_name','product_photos_qty','product_weight_g', 'product_length_cm','product_height_cm','product_width_cm','customer_state','price']]\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Remove outliers\n",
    "    df = df[(df['price'] >= df['price'].quantile(0.05)) & (df['price'] <= df['price'].quantile(0.95))]\n",
    "\n",
    "    # Convert categorical variables to numerical values\n",
    "    df = pd.get_dummies(df, columns=['product_category_name', 'customer_state'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train models to predict pricing\n",
    "\n",
    "### 1. Random Forest Regressor\n",
    "\n",
    "* MAE is 13.381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 13.381\n"
     ]
    }
   ],
   "source": [
    "df = prepare_dataset_random_forest(FILE_PATH + \"brazilian_ecommerce_dataset.csv\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('price', axis=1), df['price'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a machine learning model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate RF model\n",
    "y_pred = rf.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean absolute error: {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Time-series forecasting\n",
    "\n",
    "* Use Meta (formally Facebook) Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'product_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'product_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Train a time series forecasting model for each product & save those models\u001b[39;00m\n\u001b[1;32m      2\u001b[0m forecast_models \u001b[39m=\u001b[39m {}\n\u001b[0;32m----> 3\u001b[0m unique_product_ids \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mproduct_id\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39munique()\n\u001b[1;32m      5\u001b[0m \u001b[39m# For demonstration & simplicity taking only 200 products\u001b[39;00m\n\u001b[1;32m      6\u001b[0m unique_product_ids \u001b[39m=\u001b[39m unique_product_ids[\u001b[39m0\u001b[39m:\u001b[39m200\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'product_id'"
     ]
    }
   ],
   "source": [
    "# Train a time series forecasting model for each product & save those models\n",
    "forecast_models = {}\n",
    "unique_product_ids = df['product_id'].unique()\n",
    "\n",
    "# For demonstration & simplicity taking only 200 products\n",
    "unique_product_ids = unique_product_ids[0:200]\n",
    "for product in unique_product_ids:\n",
    "    product_df = df[df['product_id'] == product]\n",
    "    # Aggregate sales data by date\n",
    "    product_df['order_purchase_date'] = pd.to_datetime(product_df['order_purchase_timestamp']).dt.date\n",
    "    sales_data = product_df.groupby(['order_purchase_date']).agg({'price': 'sum'}).reset_index()\n",
    "    sales_data = sales_data.rename(columns={'order_purchase_date': 'ds', 'price': 'y'})\n",
    "    if len(sales_data)>=50:\n",
    "      # Train a time series forecasting model\n",
    "      m = Prophet()\n",
    "      m.fit(sales_data)\n",
    "      forecast_models[product] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
